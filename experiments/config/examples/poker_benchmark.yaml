# Example poker benchmarking experiment
name: "Poker Model Benchmark"
description: "Benchmark poker performance of different LLM models"

# Game configuration
game:
  type: "poker"
  starting_stack: 1000
  small_blind: 10
  big_blind: 20
  random_seed: 42  # Fixed seed for reproducibility

# Models to benchmark
models:
# Models to benchmark
models:
  - name: "gpt-4o-mini"
    provider: "openai"
    max_tokens: 1000
    temperature: 0.7
    max_retries: 3
    timeout: 60
  - name: "claude-3-haiku-20240307"
    provider: "anthropic"
    max_tokens: 1000
    temperature: 0.7
    max_retries: 3
    timeout: 60

# Number of experiment iterations
iterations: 1

# Number of hands per game
num_hands: 3

# Metrics to calculate
metrics:
  - "win_rate"
  - "avg_stack_change"
  - "hands_played"

# Output options
output:
  format: "json"
  directory: "./results"